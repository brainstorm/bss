#!/usr/bin/env python

""" Flowcell Writer Replay

    Given a UNIX "stat" input generated by:
        find . | xargs stat "%s %n %y" > flowcell_filesizes.tsv

    With contents such as:

    2402705 ./Data/Intentities/BaseCalls/L005/C171.1/s_5_2219.bcl.gz 2015-10-07 02:00:40.454831539 +0100
    2453492 ./Data/Intentities/BaseCalls/L005/C171.1/s_5_2120.bcl.gz 2015-10-07 02:00:29.917686120 +0100
    2477752 ./Data/Intentities/BaseCalls/L005/C171.1/s_5_1203.bcl.gz 2015-10-07 01:57:34.184586979 +0100
    (...)

    This script writes the directory and file structure to (stress) test
    filesystem event processing systems like:

    https://github.com/axkibe/lsyncd
    https://github.com/brainstorm/bss

    The file contents are based on /dev/urandom for now, matching the filesize in the first column of the
    TSV file.

    NOTE: The resulting directory/file structure can easily fill up your storage.
"""
import pandas as pd
import os
from time import sleep
import click
import logging

log = logging.getLogger(__name__)
log.setLevel(logging.DEBUG)

ch = logging.StreamHandler()
ch.setLevel(logging.INFO)

log.addHandler(ch)

VIRTUAL_FLOWCELL_DIR='virtual_fc'
ILLUMINA_FILESIZES='flowcell_filesizes.tsv.gz'

@click.command()
@click.option('-f', '--flowcell',
              type=click.Path(),
              default=VIRTUAL_FLOWCELL_DIR,
              help="Flowcell directory structure and files will be created here."
)

@click.option('-s', '--sizesfile',
              type=click.Path(exists=True),
              default=ILLUMINA_FILESIZES,
              help="Filesizes and timeseries of illumina basecalls created over time."
)
def main(flowcell, sizesfile):
    # y[0:15] is clipping the last 3 digits of the microseconds since
    # https://docs.python.org/2/library/datetime.html#strftime-strptime-behavior
    # states that: "the %f directive accepts from one to six digits and zero pads
    # on the right... stat returned 9 digits instead of 6"

    dateparse = lambda x,y: pd.datetime.strptime(x+" "+y[0:15],'%Y-%m-%d %H:%M:%S.%f')

    log.info("Loading Illumina(tm) write activity timeseries... ")
    flowcell_writes = pd.read_table(sizesfile, parse_dates={'datetime' : ["date", "time"]},
                                    index_col='datetime', date_parser = dateparse, sep=' ',
                                    names=['size', 'filename', 'date', 'time', 'offset'])
    del flowcell_writes['offset']

    # Order timeseries and calculate deltas between file creation
    flowcell_writes.sort_index(ascending=True, inplace=True)
    flowcell_writes['deltas'] = flowcell_writes.index.difference(flowcell_writes).to_series().diff().fillna(0)

    only_bcl = flowcell_writes[flowcell_writes["filename"].str.contains(".bcl")]

    log.info("Replaying write activity starts!")
    # Iterate over the pandas dataframe, creating the directories and file objects.
    for event in only_bcl.values:
        size, filename, delta = event[0], event[1], event[2]
        delay = delta.total_seconds()
        log.info("Waiting for {delay} seconds to generate {bcl}... ".format(delay=delay, bcl=filename))
        # Wait for the amount of seconds that the real machine takes to write the file(s)
        sleep(delay)

        log.info("Generating {bytes} bytes for {bcl}... ".format(bytes=size, bcl=filename))

        if not os.path.exists(os.path.join(flowcell, os.path.dirname(filename))):
            try:
                os.makedirs(os.path.join(flowcell, os.path.dirname(filename)))
            except OSError as exc: # Guard against race condition
                if exc.errno != errno.EEXIST:
                    raise

        with open(os.path.join(flowcell, filename), 'wb+') as bcl:
            with open("/dev/urandom", "rb") as rnd:
                # XXX: Approximate this better, need to finetune filesizes
                for bytes in xrange(size/100):
                    bcl.write(rnd.readline())


if __name__ == '__main__':
    main()
